\section{各実験における考察}
\subsection{DenseNetを用いた内視鏡画像からの\\マルチラベル予測における考察}
図\ref{fig:densenet121_result_process}、\ref{fig:densenet121_e_result_process}、\ref{fig:densenet161_result_process}、\ref{fig:densenet161_e_result_process}の学習過程を見ると、分類器拡張を入れておらず複雑なモデルを用いている図\ref{fig:densenet161_result_process}のモデル３のみ損失が安定せずに学習に失敗している。それに対して図\ref{fig:densenet121_result_process}のモデル１、図\ref{fig:densenet121_e_result_process}のモデル２、図\ref{fig:densenet161_e_result_process}のモデル４では、損失がエポックが進むごとに減っていて、かつAccとAllAccの両方が上昇していることから、学習がきちんと進んでいることがわかる。またこれらのモデルでは、訓練損失が減少を続けているのに対して、検証損失が学習途中から上昇に転じている。これはデータに関して過学習を起こしているが、DenseNet121からDenseNet161に増やしたのに関わらず変化がないことから、これはモデルの大きさによって特徴表現が狭まっているわけではない。マルチラベル学習でバイナリ交差エントロピーを用いていることから、モデルの学習が進んで予測されるラベルが増えるに従って損失が増えやすくなっていると考えられる。また各画像をマルチラベルと関連付けて学習するこの手法では、病変がある患者において、病変が全く見られない部位の画像も病変の存在を示すマルチラベルと学習するために学習が安定しずらいと考えられる。しかしAccやF1-Scoreが良くなっていることから、学習は問題なく進んでいると見なすことができる。また分類器拡張に関してはDenseNet121に関しては図\ref{fig:densenet121_result_process}のモデル１より図\ref{fig:densenet121_e_result_process}のモデル２の方が学習後半での検証損失の上昇幅やF1-Scoreの減少幅が小さくなっており、学習の安定化に効果があったことがわかる。DenseNet161に関しても図\ref{fig:densenet161_result_process}のモデル３が学習に失敗しているのに対して、図\ref{fig:densenet161_e_result_process}のモデル４は学習が進んでおり、学習の安定化に分類器拡張が効果があったことがわかる。
またすべてのモデルで過学習が始まる前に最高精度を記録しており、次の検証結果でも示されているように、どのモデルでも予測性能に大きな差異はなかった。

表\ref{tb:densenet121}、表\ref{tb:densenet121_e}、表\ref{tb:densenet161}、表\ref{tb:densenet161_e}の検証結果を見ると、どのモデルでもAllAccが30\%を超えていて、F1-Scoreも70\%を超えており、きちんと学習されていることがわかる。しかしこの結果には複数の問題がある。AllAccに関しては、マルチラベルの中でもそもそもラベルが真になっている部分の少ない教師データの際に予測ができているだけの可能性が高い。F1-Scoreもマルチラベルの一つ目の病変が１つでもあるかどうかのラベルの推論結果が良いために、全体の結果が良くなっていると考えられる。このためマルチラベルの検証結果を一つ目のラベルと二つ目以降のラベルに分離した結果を提示した。この結果を見ると、表\ref{tb:densenet121}のモデル１と表\ref{tb:densenet121_e}のモデル２と表\ref{tb:densenet161_e}のモデル４では、一つ目のラベルはPrecisionとRecallともに98\%を超えていて、病変があるかどうかの判定は高い精度を持っていることがわかる。また二つ目以降のラベルでも表\ref{tb:densenet121}のモデル１では、Precisionが77\%、Recallが42\%、F1-Scoreが54\%と判定がある程度はできていることがわかる。本実験ではマルチラベル全体でのF1-Scoreが最も良いものを次の実験でも用いるためモデル１を選択した。

検証結果では推論時のマルチラベルの二値化の際のしきい値が0.5に設定されているが、テストの際にはしきち値を0.1から0.9まで0.1ずつ変化させてPrecisionとRecallの推移を見た。PrecisionとRecallの値の性質上、両者はトレードオフの関係にあり、しきち値が低いとRecallが上がり、高いとPrecisionが上がる。
しきい値を変化させた際の適合率と再現率の変化の確認実験の結果、\ref{fig:densenet121_result_threshold}のように、しきち値が0.3のときに両者がバランス良く、F1-Scoreが一番高かった。またしきい値が0.1のときにRecallが85\%と一番高く、しきい値が0.7のときにPrecisionが77\%と一番高くなった。

この結果を用いて本研究での提案システムとしては、しきい値が0.7のときの結果を予測の範囲は狭いが信頼度の高い予測として、しきい値が0.1のときの結果を信頼度は低いが広範囲の予測として用いる。これにより、医師の診断時の判断の支援も行える。

\subsection{3D-ResNetを用いた内視鏡画像からの\\マルチラベル予測における考察}
3D-ResNetを用いた実験ではDenseNetでの場合と同様に、図\ref{fig:resnet3d_result_process}、図\ref{fig:resnet3d_e_result_process}、図\ref{fig:resnet3d_m_result_process}、図\ref{fig:resnet3d_e_m_result_process}を見ると、損失の推移やAccとAllAccの値から学習が問題なく行われていると見なすことができる。またDenseNetの場合とは異なり、学習回数が進んでも訓練損失と検証損失の差が開いておらず、過学習が抑えられていると。これは各患者ごとに画像を時間軸で連結した三次元データを用いていることから、全く関係ない特徴量とマルチラベルが学習されることが減り、学習が安定したことが考えられる。しかしAllAccやF1-ScoreがDenseNetと比べてわずかに低くなっている。これは3D-CNNを用いたことにより、特徴抽出部分の最終層での特徴の合算の際に特徴が多少消失してしまったためであると考えられる。また分類器拡張に関しては、図\ref{fig:resnet3d_result_process}のモデル１と図\ref{fig:resnet3d_e_result_process}のモデル２を比較したときと、図\ref{fig:resnet3d_m_result_process}のモデル３と図\ref{fig:resnet3d_e_m_result_process}のモデル４を比較したときのどちらも分類器拡張を導入したほうが検証損失の上昇やF1-Scoreの減少が抑えられており、効果が確認できる。また図\ref{fig:resnet3d_result_process}のモデル１と図\ref{fig:resnet3d_e_result_process}のモデル２で用いた平均プーリングと図\ref{fig:resnet3d_m_result_process}のモデル３と図\ref{fig:resnet3d_e_m_result_process}のモデル４で用いた最大プーリングで大きな差がでなかったのは最終プーリング層での特徴消失の度合いがどちらの方法でもほぼ変わらないためだと考えられる。

表\ref{tb:resnet3d}、表\ref{tb:resnet3d_e}、表\ref{tb:resnet3d_m}、表\ref{tb:resnet3d_e_m}の検証結果はDenseNetの場合と同様に、一つ目のラベルはPrecisionとRecallともに98\%を超えていて、病変があるかどうかの判定は高い精度を持っていることがわかる。また二つ目以降のラベルでも表\ref{tb:densenet121}、表\ref{tb:densenet121_e}、表\ref{tb:densenet161}、表\ref{tb:resnet3d}のモデル１でPrecisionが71\%、Recallが39\%、F1-Scoreが50\%と判定がある程度はできていることがわかる。しかし検証結果も学習過程での見られたのと同じ傾向があり、DenseNetよりもわずかに結果が低くなっている。本実験でもDenseNetと同様に予測性能ではどのモデルでも大きく変わらないが、最もF1-Scoreの良いモデル１を次の実験で用いた。

図\ref{fig:resnet3d_result_threshold}の推論時のマルチラベルの二値化の際のしきい値の推移を見ると、しきい値が0.2のときにPrecisionとRecallのバランスが良く、F1-Scoreが一番高かった。またしきい値が0.1のときにRecallが83\%と一番高く、しきい値が0.9のときにPrecisionが88\%と一番高かった。しかし、しきい値が0.9のときはRecallが9\%、F1-Scoreも17\%と非常に低くなっている。このためしきい値が高すぎて予測ラベルが少なすぎる状態になっていると考えられるため、しきい値が0.7のときがPrecisionが75\%かつRecallが34\%と信頼度の高い予測として有用だとみなすことができる。これにより、その他の結果と同様に3D-ResNetのときはDenseNetのときよりも少し精度が低いという結果になった。

\section{全体における考察}
画像を個別に入力する手法と画像を患者ごとにまとめて入力する手法の両方で非常に有用な結果が出たと言える。画像を患者ごとにまとめて入力する手法のほうが、関係ない特徴とラベルの学習がなくなるために学習は安定する。それに対して画像を個別に入力する手法の方は、学習は不安定化する。しかし予測の際も１枚ずつ予測し、その結果を患者ごとに集約するために、間違った予測が弱まり、正しい予測が重ね合わさることで、患者単位の予測では高い精度を出すことに成功した。どちらの手法のモデルでもしきち値の変更でPrecisionが70\%前後の予測を信頼度の高い予測として、Recallが80\%前後の予測を信頼度は低いが可能性としてはありえる予測として提供することができ、診断の際の判断の支援と見逃しの防止の両方を満たすシステムとして利用することができる。
